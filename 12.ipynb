{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_codXTgCGLZ"
      },
      "source": [
        "# Lab 3: Constituency parsing with CKY\n",
        "\n",
        "The grammatical structure of a sentence can be represented with a Context Free Grammar (CFG). When we additionally assign probabilities to the rules of the CFG we get a PCFG: a _Probabilistic_ CFG.\n",
        "\n",
        "Given a sufficiently expressive PCFG (one that holds enough rules) we can parse new sentences using the Cocke–Kasami–Younger (CKY) algorithm. You can use this algorithm in three ways: to find the set of all the possible parses $p$ of a sentence $s$ under a PCFG $G$; to find the probability of the sentence by summing up the probabilities of these parses; or to find the parse $p^{*}$ of the highest probability.\n",
        "\n",
        "\n",
        "### Tasks\n",
        "1. In this notebook you will learn how to represent a PCFG in an object-oriented manner as a collection of python classes. These classes are already defined for you. Read them through thoroughly and make sure that you understand them well. You have to use them in task 2.\n",
        "\n",
        "2. Implement the CKY algorithm to find the most probable parse $p^{*}$ for a sentence. Your implementation will follow the psuedo-code that is given in both the lecture slides, and Jurafsky and Martin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2bCocjNWhJe"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q2rFTz2rCGLd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "# nltk will be used to draw constituency parses\n",
        "import nltk\n",
        "from nltk.tree import Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5N77nlCWcvs",
        "outputId": "54039d49-de91-4734-b6ee-0b6948669c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-13 20:32:44 URL:https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-1.txt [337/337] -> \"groucho-grammar-1.txt\" [1]\n",
            "2023-06-13 20:32:45 URL:https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-2.txt [337/337] -> \"groucho-grammar-2.txt\" [1]\n",
            "2023-06-13 20:32:46 URL:https://naturallogic.pro/_files_/download/mNLP/telescope-grammar.txt [381/381] -> \"telescope-grammar.txt\" [1]\n"
          ]
        }
      ],
      "source": [
        "# downloading grammar files\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-1.txt\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/groucho-grammar-2.txt\n",
        "! wget -nv https://naturallogic.pro/_files_/download/mNLP/telescope-grammar.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA7SNulWbMf5"
      },
      "source": [
        "# PCFG\n",
        "\n",
        "In this lab we will show you a way to represent a **PCFG** using python objects. We will introduce the following classes:\n",
        "\n",
        "* Symbol\n",
        "    * Terminal\n",
        "    * Nonterminal\n",
        "* Rule\n",
        "\n",
        "At first glance, this might seem like a lot of work. But, hopefully, by the time you get to implementing CKY you will be convinced in the benefits of these constructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X2Nk5i3CGLg"
      },
      "source": [
        "## Symbol\n",
        "\n",
        "Recall that:\n",
        "* **Terminal** symbols are the words of the sentence: _I, ate, salad, the_ etc.\n",
        "* **Nonterminal** symbols are the syntactic categories of the various constituents: _S, NP, VP, Det_ etc.\n",
        "\n",
        "In our representation, `Symbol` is going to be a container class. The classes `Terminal` and `Nonterminal` will *inherit* from the `Symbol` class and will hence both become a type of symbol. The classes themselves are effectively a container for the underlying python strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VlsXWvTjCGLh"
      },
      "outputs": [],
      "source": [
        "class Symbol:\n",
        "    \"\"\"\n",
        "    A symbol in a grammar.\n",
        "    This class will be used as parent class for Terminal, Nonterminal.\n",
        "    This way both will be a type of Symbol.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Terminal(Symbol):\n",
        "    \"\"\"\n",
        "    Terminal symbols are words in a vocabulary\n",
        "\n",
        "    E.g. 'I', 'ate', 'salad', 'the'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol: str):\n",
        "        assert type(symbol) is str, f\"A Terminal takes a python string, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return True\n",
        "\n",
        "    def is_nonterminal(self):\n",
        "        return False\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"'{self._symbol}'\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Terminal({repr(self._symbol)})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self._symbol)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"The length of the underlying python string\"\"\"\n",
        "        return len(self._symbol)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self._symbol < other._symbol\n",
        "\n",
        "    @property\n",
        "    def obj(self):\n",
        "        \"\"\"Returns the underlying python string\"\"\"\n",
        "        return self._symbol\n",
        "\n",
        "\n",
        "class Nonterminal(Symbol):\n",
        "    \"\"\"\n",
        "    Nonterminal symbols are the grammatical classes in a grammar.\n",
        "\n",
        "    E.g. S, NP, VP, N, Det, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol: str):\n",
        "        assert type(symbol) is str, f\"A Nonterminal takes a python string, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "\n",
        "    def is_terminal(self):\n",
        "        return False\n",
        "\n",
        "    def is_nonterminal(self):\n",
        "        return True\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"[{self._symbol}]\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Nonterminal({repr(self._symbol)})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self._symbol)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"The length of the underlying python string\"\"\"\n",
        "        return len(self._symbol)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self._symbol < other._symbol\n",
        "\n",
        "    @property\n",
        "    def obj(self):\n",
        "        \"\"\"Returns the underlying python string\"\"\"\n",
        "        return self._symbol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ0WmVOZCGLj"
      },
      "source": [
        "Let's try out the classes by initializing some terminal and nonterminal symbols:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vv2qVwloCGLk"
      },
      "outputs": [],
      "source": [
        "dog = Terminal('dog')\n",
        "the = Terminal('the')\n",
        "walks = Terminal('walks')\n",
        "\n",
        "S = Nonterminal('S')\n",
        "NP = Nonterminal('NP')\n",
        "NP_prime = Nonterminal('NP')\n",
        "VP = Nonterminal('VP')\n",
        "V = Nonterminal('V')\n",
        "N = Nonterminal('N')\n",
        "Det = Nonterminal('Det')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGZHKNAUCGLl"
      },
      "source": [
        "The methods `__eq__` and `__ne__` make it possible to compare our objects using standard Python syntax. But more importantly: compare in the way that we are interested in, namely whether the underlying representation is the same.\n",
        "\n",
        "To see the difference, try commenting out the method `__eq__` in the class above, and notice the different result of the equality test `NP==NP_prime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKWBrXghCGLl",
        "outputId": "e6b5a47f-4b87-41b4-983a-f9348adf55ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'dog'\n",
            "[NP]\n",
            "\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(dog)\n",
        "print(NP)\n",
        "print()\n",
        "print(NP==Det)\n",
        "print(NP!=Det)\n",
        "print(NP==NP)\n",
        "print(NP==NP_prime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qScfOAVvCGLm"
      },
      "source": [
        "Note the difference between calling `print(NP)` and simply calling `NP`. The first is taken care of by the method `__str__` and the second by the method `__repr__`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTS_97wYCGLo",
        "outputId": "065d184b-61d8-46af-c768-c3a2222156cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Terminal('dog')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXMlXaFkCGLo"
      },
      "source": [
        "We can also easily check if our symbol is a terminal or not:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMuoMVHQCGLp",
        "outputId": "87f64509-4a7a-4d6e-fb6e-77e09fe572f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dog.is_terminal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtnXm0IUCGLq",
        "outputId": "4b34f6ac-0377-4a4c-dd91-2ba5fd915c2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NP.is_terminal()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvtkwhBhCGLq"
      },
      "source": [
        "Finally the method `__hash__` makes our object *hashable*, and hence usable in a datastructure like a dictionary.\n",
        "\n",
        "Try commenting out this method above in the class and then retry constructing the dictionary: notice the error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nniQ14QyCGLr",
        "outputId": "77229b80-08f2-4fbd-9599-8b3b92ff2f80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{Nonterminal('NP'): 1, Nonterminal('S'): 2}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = {NP: 1, S: 2}\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpC5JyBcCGLs"
      },
      "source": [
        "## Rules\n",
        "\n",
        "In a PCFG a **rule** looks something like this\n",
        "\n",
        "$$NP \\to Det\\;N$$\n",
        "\n",
        "with a corresponding probability, for example $1.0$ if we lived in a world where all noun phrases had this grammatical structure.\n",
        "\n",
        "In our representation, `Rule` will be an object made of a left-hand side (`lhs`) symbol, a sequence of right-hand side symbols (`rhs`) and a probability `prob`.\n",
        "\n",
        "If we use the above defined symbols, we can call\n",
        "\n",
        "    rule = Rule(NP, [Det, N], 1.0)\n",
        "\n",
        "This will construct an instance called `rule` which represent the rule above\n",
        "\n",
        "    [NP] -> [Det] [N] (1.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vXN4G4t-CGLs"
      },
      "outputs": [],
      "source": [
        "class Rule:\n",
        "\n",
        "    def __init__(self, lhs, rhs, prob):\n",
        "        \"\"\"\n",
        "        Constructs a Rule.\n",
        "        A Rule takes a LHS symbol and a list/tuple of RHS symbols.\n",
        "\n",
        "        :param lhs: the LHS nonterminal\n",
        "        :param rhs: a sequence of RHS symbols (terminal or nonterminal)\n",
        "        :param prob: probability of the rule\n",
        "        \"\"\"\n",
        "\n",
        "        assert isinstance(lhs, Symbol), 'LHS must be an instance of Symbol (actually even a non-terminal but later we will expan LHS)'\n",
        "        assert len(rhs) > 0, 'If you want an empty RHS, use an epsilon Terminal EPS'\n",
        "        assert all(isinstance(s, Symbol) for s in rhs), 'RHS must be a sequence of Symbol objects'\n",
        "        if prob is not None:\n",
        "            assert 0 <= prob <= 1, 'The probability must be between 0 and 1'\n",
        "        self._lhs = lhs\n",
        "        self._rhs = tuple(rhs)\n",
        "        self._prob = prob\n",
        "\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self._lhs == other._lhs and self._rhs == other._rhs and self._prob == other._prob\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self._lhs, self._rhs, self._prob))\n",
        "\n",
        "    def __repr__(self):\n",
        "        rhs = ' '.join(str(sym) for sym in self._rhs)\n",
        "        return f\"{self._lhs} -> {rhs} ({self.prob})\"\n",
        "\n",
        "    def is_binary(self):\n",
        "        \"\"\"True if Rule is binary: A -> B C\"\"\"\n",
        "        return len(self._rhs) == 2\n",
        "\n",
        "    def is_unary(self):\n",
        "        \"\"\"True if Rule is unary: A -> w\"\"\"\n",
        "        return len(self._rhs) == 1\n",
        "\n",
        "    @property\n",
        "    def lhs(self):\n",
        "        \"\"\"Returns the lhs of the rule\"\"\"\n",
        "        return self._lhs\n",
        "\n",
        "    @property\n",
        "    def rhs(self):\n",
        "        \"\"\"Returns the rhs of the rule\"\"\"\n",
        "        return self._rhs\n",
        "\n",
        "    @property\n",
        "    def prob(self):\n",
        "        \"\"\"Returns the probability of the rule\"\"\"\n",
        "        return self._prob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4U1gI2rCGLt"
      },
      "source": [
        "Just as with `Terminal` and `Nonterminal` you can print an instance of `Rule`, you can access its attributes, and you can hash rules with containers such as dict and set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld0VMQWWCGLu",
        "outputId": "91ae9c36-0bb3-4906-fc9b-158d6561788e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[S] -> [NP] [VP] (1.0)\n",
            "[NP] -> [Det] [N] (1.0)\n",
            "[N] -> 'dog' (1.0)\n",
            "[Det] -> 'the' (1.0)\n"
          ]
        }
      ],
      "source": [
        "r1 = Rule(S, [NP, VP], 1.0)\n",
        "r2 = Rule(NP, [Det, N], 1.0)\n",
        "r3 = Rule(N, [dog], 1.0)\n",
        "r4 = Rule(Det, [the], 1.0)\n",
        "r5 = Rule(VP, [walks], 1.0)\n",
        "\n",
        "print(r1)\n",
        "print(r2)\n",
        "print(r3)\n",
        "print(r4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y62yZ8I8CGLv",
        "outputId": "1d33e06d-ba1c-4f8e-a724-3040abb82b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "print(r1.prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhEJETHgCGLv",
        "outputId": "10d165b0-7983-4c61-a3d3-bb53e50286e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r1 in set([r1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTAJ2CmBCGLw",
        "outputId": "f7623990-a5a3-479d-b637-4e18c717780f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{[S] -> [NP] [VP] (1.0): 1, [NP] -> [Det] [N] (1.0): 2}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = {r1: 1, r2: 2}\n",
        "d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrHaNQzKCGLw"
      },
      "source": [
        "## Grammar\n",
        "\n",
        "A `PCFG` class is a container for `Rules`. The `Rules` are stored in the `PCFG` in such a way that they can be accesed easily in different ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sm6tzk7TCGLw"
      },
      "outputs": [],
      "source": [
        "class PCFG(object):\n",
        "    \"\"\"\n",
        "    Constructs a PCFG.\n",
        "    A PCFG stores a list of rules that can be accessed in various ways.\n",
        "\n",
        "    :param rules: an optional list of rules to initialize the grammar with\n",
        "    \"\"\"\n",
        "    def __init__(self, rules=[]):\n",
        "        self._rules = []\n",
        "        self._rules_by_lhs = defaultdict(list)\n",
        "        self._terminals = set()\n",
        "        self._nonterminals = set()\n",
        "        for rule in rules:\n",
        "            self.add(rule)\n",
        "\n",
        "    def add(self, rule):\n",
        "        \"\"\"Adds a rule to the grammar\"\"\"\n",
        "        if not rule in self._rules:\n",
        "            self._rules.append(rule)\n",
        "            self._rules_by_lhs[rule.lhs].append(rule)\n",
        "            self._nonterminals.add(rule.lhs)\n",
        "            for s in rule.rhs:\n",
        "                if s.is_terminal():\n",
        "                    self._terminals.add(s)\n",
        "                else:\n",
        "                    self._nonterminals.add(s)\n",
        "\n",
        "    def update(self, rules):\n",
        "        \"\"\"Add a list of rules to the grammar\"\"\"\n",
        "        for rule in rules:\n",
        "            self.add(rule)\n",
        "\n",
        "    @property\n",
        "    def nonterminals(self):\n",
        "        \"\"\"The list of nonterminal symbols in the grammar\"\"\"\n",
        "        return self._nonterminals\n",
        "\n",
        "    @property\n",
        "    def terminals(self):\n",
        "        \"\"\"The list of terminal symbols in the grammar\"\"\"\n",
        "        return self._terminals\n",
        "\n",
        "    @property\n",
        "    def rules(self):\n",
        "        \"\"\"The list of rules in the grammar\"\"\"\n",
        "        return self._rules\n",
        "\n",
        "    @property\n",
        "    def binary_rules(self):\n",
        "        \"\"\"The list of binary rules in the grammar\"\"\"\n",
        "        return [rule for rule in self._rules if rule.is_binary()]\n",
        "\n",
        "    @property\n",
        "    def unary_rules(self):\n",
        "        \"\"\"The list of unary rules in the grammar\"\"\"\n",
        "        return [rule for rule in self._rules if rule.is_unary()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._rules)\n",
        "\n",
        "    def get(self, lhs):\n",
        "        \"\"\"The list of rules whose LHS is the given symbol lhs\"\"\"\n",
        "        return self._rules_by_lhs.get(lhs, [])\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Iterator over rules (in arbitrary order)\"\"\"\n",
        "        return iter(self._rules)\n",
        "\n",
        "    def iteritems(self):\n",
        "        \"\"\"Iterator over pairs of the kind (LHS, rules rewriting LHS)\"\"\"\n",
        "        return self._rules_by_lhs.items()\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Prints the grammar line by line\"\"\"\n",
        "        lines = []\n",
        "        for lhs, rules in self.iteritems():\n",
        "            for rule in rules:\n",
        "                lines.append(str(rule))\n",
        "        return '\\n'.join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcGZAbUSCGLx"
      },
      "source": [
        "Initialize a grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pIVuStsyCGLy"
      },
      "outputs": [],
      "source": [
        "G = PCFG()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVkm-al_CGLy"
      },
      "source": [
        "We can add rules individually with `add`, or as a list with `update`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j-d55FW6CGLy"
      },
      "outputs": [],
      "source": [
        "G.add(r1)\n",
        "G.update([r2,r3,r4,r5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "f-3Mf4JPCGLy"
      },
      "source": [
        "We can print the grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZNR4GxqCGLy",
        "outputId": "936ebe3a-8738-4936-9709-908a0dc984f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[S] -> [NP] [VP] (1.0)\n",
            "[NP] -> [Det] [N] (1.0)\n",
            "[N] -> 'dog' (1.0)\n",
            "[Det] -> 'the' (1.0)\n",
            "[VP] -> 'walks' (1.0)\n"
          ]
        }
      ],
      "source": [
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpEzw7CSCGLz"
      },
      "source": [
        "We can get the set of rewrite rules for a certain LHS symbol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvJI3GIPCGLz",
        "outputId": "fd0d7d48-50bc-4135-9f1a-699b7f96e5de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[S] -> [NP] [VP] (1.0)]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.get(S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3cghJx6CGL0",
        "outputId": "6bcc374c-3b8c-4789-8a02-508196797b8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[NP] -> [Det] [N] (1.0)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.get(NP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNh0XOhuCGL0"
      },
      "source": [
        "We can also iterate through rules in the grammar.\n",
        "\n",
        "Note that the following is basically counting how many rules we have in the grammar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXVqzI9lCGL1",
        "outputId": "16637eff-57a3-4557-9f01-cc2f50a61f46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(1 for r in G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jjU3krCCGL1"
      },
      "source": [
        "which can also be done in a more efficient way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vi814lRCGL2",
        "outputId": "e1cf6362-b64f-4299-cc3b-9494d540e911"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l7BmtlyCGL2"
      },
      "source": [
        "We can access the set of terminals and nonterminals of the grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9--IbP75CGL2",
        "outputId": "7b7b4db6-5ddb-4558-f329-1003512095bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{Nonterminal('VP'), Nonterminal('S'), Nonterminal('Det'), Nonterminal('NP'), Nonterminal('N')}\n"
          ]
        }
      ],
      "source": [
        "print(G.nonterminals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MvItFKtCGL2",
        "outputId": "dbea94ab-c53a-43da-b56a-c2d11361fbb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{Terminal('walks'), Terminal('dog'), Terminal('the')}\n"
          ]
        }
      ],
      "source": [
        "print(G.terminals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q29uTBaXCGL3",
        "outputId": "dc5916c0-2d13-4735-d3af-4bb7eedb41d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "S in G.nonterminals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsVg9Wf2CGL3",
        "outputId": "99446ec7-d60e-46e8-9744-a1958bc6c40f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dog in G.terminals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ojHdLHUCGL4"
      },
      "source": [
        "Finally we can easily access all the binary rules and all the unary rules in the grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv6pcFS1CGL4",
        "outputId": "05ae2cdf-a46e-4630-f61f-d24e8ac7d740"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[N] -> 'dog' (1.0), [Det] -> 'the' (1.0), [VP] -> 'walks' (1.0)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.unary_rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYpJIx4mCGL4",
        "outputId": "8f42e2c5-7f0c-449e-adcd-199a7a69d0b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[S] -> [NP] [VP] (1.0), [NP] -> [Det] [N] (1.0)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.binary_rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZdbicfrCGL5"
      },
      "source": [
        "# Visualizing a tree\n",
        "\n",
        "For the sake of legacy let's reiterate an age-old NLP schtick, the well-known example of structural ambiguity from the Groucho Marx movie, [Animal Crackers](https://youtu.be/FZUfhfHbjE4?t=1m33s) (1930):\n",
        "\n",
        "> One morning I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\n",
        "\n",
        "Let's take a closer look at the ambiguity in the phrase: _I shot an elephant in my pajamas_. The ambiguity is caused by the fact that the sentence has two competing parses represented in:\n",
        "\n",
        "    (S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\n",
        "\n",
        "and\n",
        "\n",
        "    (S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\n",
        "\n",
        "\n",
        "We can write these parses down as strings and then let NLTK turn them into trees using the NLTK `Tree` class. (See http://www.nltk.org/api/nltk.html#nltk.tree.Tree as reference for this class, if you want to know more.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dDFH2wyqCGL5"
      },
      "outputs": [],
      "source": [
        "parse1 = \"(S (NP I) (VP (VP (V shot) (NP (Det an) (N elephant))) (PP (P in) (NP (Det my) (N pajamas)))))\"\n",
        "parse2 = \"(S (NP I) (VP (V shot) (NP (Det an) (NP (N elephant) (PP (P in) (NP (Det my) (N pajamas)))))))\"\n",
        "\n",
        "pajamas1 = Tree.fromstring(parse1)\n",
        "pajamas2 = Tree.fromstring(parse2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjQ_EvhHCGL5"
      },
      "source": [
        "We can then *pretty-print* these trees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSsl34LCCGL6",
        "outputId": "d07e47a4-4078-432d-cdce-168fe3417a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     S                                       \n",
            "  ___|______________                          \n",
            " |                  VP                       \n",
            " |         _________|__________               \n",
            " |        VP                   PP            \n",
            " |    ____|___              ___|___           \n",
            " |   |        NP           |       NP        \n",
            " |   |     ___|_____       |    ___|_____     \n",
            " NP  V   Det        N      P  Det        N   \n",
            " |   |    |         |      |   |         |    \n",
            " I  shot  an     elephant  in  my     pajamas\n",
            "\n",
            "     S                                       \n",
            "  ___|__________                              \n",
            " |              VP                           \n",
            " |    __________|______                       \n",
            " |   |                 NP                    \n",
            " |   |     ____________|___                   \n",
            " |   |    |                NP                \n",
            " |   |    |      __________|___               \n",
            " |   |    |     |              PP            \n",
            " |   |    |     |       _______|___           \n",
            " |   |    |     |      |           NP        \n",
            " |   |    |     |      |        ___|_____     \n",
            " NP  V   Det    N      P      Det        N   \n",
            " |   |    |     |      |       |         |    \n",
            " I  shot  an elephant  in      my     pajamas\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pajamas1.pretty_print()\n",
        "pajamas2.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjAkmuXCGL7"
      },
      "source": [
        "# Parsing with CKY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8pVcXseCGL8"
      },
      "source": [
        "Let's stick with this sentence for the rest of this lab. We will use CKY to find the 'best' parse for this sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GWkI8S1kCGL8"
      },
      "outputs": [],
      "source": [
        "# Turn the sentence into a list\n",
        "sentence = \"I shot an elephant in my pajamas\".split()\n",
        "# The length of the sentence\n",
        "num_words = len(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtehwdb1CGL8"
      },
      "source": [
        "A PCFG for this sentence can be found in the file `groucho-grammar-1.txt`. We read this in with the function `read_grammar_rules`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eVASx2r0CGL9"
      },
      "outputs": [],
      "source": [
        "def read_grammar_rules(istream):\n",
        "    \"\"\"Reads grammar rules formatted as 'LHS ||| RHS ||| PROB'.\"\"\"\n",
        "    for line in istream:\n",
        "        line = line.strip()\n",
        "        if not line: continue\n",
        "        fields = line.split('|||')\n",
        "        if len(fields) != 3:\n",
        "            raise ValueError(f\"Three fields were expected: {fields}\")\n",
        "        lhs = fields[0].strip()\n",
        "\n",
        "        if lhs.startswith('[') and lhs.endswith(']'):\n",
        "            lhs = Nonterminal(lhs[1:-1])\n",
        "        else:\n",
        "            raise ValueError(f\"LHS must be a non-terminal: {fields}\")\n",
        "        rhs = fields[1].strip().split()\n",
        "        new_rhs = []\n",
        "        for r in rhs:\n",
        "            if r.startswith('[') and r.endswith(']'):\n",
        "                r = Nonterminal(r[1:-1])\n",
        "            else:\n",
        "                r = Terminal(r)\n",
        "            new_rhs.append(r)\n",
        "\n",
        "        prob = float(fields[2].strip())\n",
        "        yield Rule(lhs, new_rhs, prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UP_-I5XCGL9",
        "outputId": "dd77541e-23a9-47dc-f44c-36d366321387",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The grammar:\n",
            " [S] -> [NP] [VP] (1.0)\n",
            "[PP] -> [P] [NP] (1.0)\n",
            "[NP] -> [Det] [N] (0.2)\n",
            "[NP] -> [Det] [NP] (0.3)\n",
            "[NP] -> [N] [PP] (0.3)\n",
            "[NP] -> 'I' (0.2)\n",
            "[VP] -> [V] [NP] (0.4)\n",
            "[VP] -> [VP] [PP] (0.6)\n",
            "[Det] -> 'an' (0.6)\n",
            "[Det] -> 'my' (0.4)\n",
            "[N] -> 'elephant' (0.5)\n",
            "[N] -> 'pajamas' (0.5)\n",
            "[V] -> 'shot' (1.0)\n",
            "[P] -> 'in' (1.0)\n"
          ]
        }
      ],
      "source": [
        "# Read in the grammar\n",
        "with open('groucho-grammar-1.txt') as F:\n",
        "    grammar = PCFG(read_grammar_rules(F))\n",
        "print(\"The grammar:\\n\", grammar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRecCE1RCGL-"
      },
      "source": [
        "We will also need the following two dictionaries: `nonterminal2index` mapping from nonterminals to integers (indices); and its inverse, an `index2nonterminal` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjPcYJQuCGL-",
        "outputId": "373e9455-2bb6-4d5c-9b52-a8e64477387f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{Nonterminal('Det'): 0,\n",
              " Nonterminal('N'): 1,\n",
              " Nonterminal('NP'): 2,\n",
              " Nonterminal('P'): 3,\n",
              " Nonterminal('PP'): 4,\n",
              " Nonterminal('S'): 5,\n",
              " Nonterminal('V'): 6,\n",
              " Nonterminal('VP'): 7}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_nonterminals = len(grammar.nonterminals)\n",
        "\n",
        "# Make a nonterminal2index and a index2nonterminal dictionary\n",
        "n2i = defaultdict(lambda: len(n2i))\n",
        "i2n = dict()\n",
        "\n",
        "# sort nonterminals to make the mapping deterministic\n",
        "for nt in sorted(grammar.nonterminals):\n",
        "    i2n[n2i[nt]] = nt\n",
        "\n",
        "# Stop defaultdict behavior of n2i\n",
        "n2i = dict(n2i)\n",
        "\n",
        "n2i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x_4Mb1xCGL-"
      },
      "source": [
        "## The charts\n",
        "\n",
        "Now we are ready to introduce the chart datastructures. We need a chart to store the **scores** and a chart to store the **backpointers**.\n",
        "\n",
        "Both of these will be 3-dimensional numpy arrays: one named `score` holding the probabilities of intermediate results; one named `back` to store the backpointers in. We will use the following indexing convention for these charts:\n",
        "\n",
        "* Format of the chart holding the **scores** `score[A][begin][end] = probability`.\n",
        "This is interpreted as the probability of the constituent between `begin:end` being parsed with `A` as its root.\n",
        "\n",
        "* Format of the chart holding the **backpointers** `back[A][begin][end] = (split, B, C)`.\n",
        "This is interpreted as the constituent `begin:end` can be combined with a rule `A -> B C` where `begin:split` is `B` and `split:end` is `C`.\n",
        "\n",
        "This indexing convention is convenient for printing. See what happens when we print `back` below: we get `num_nonterminal` slices, each a numpy array of shape `[n_words+1, n_words+1]`. This is easier to read than the format `score[i][j][A]`.\n",
        "\n",
        "**[Note]** Here we pretended `A` is both the nonterminal as well as the index. In our implementation `A` will be the nonterminal and the index for `A` will be `n2i[A]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCtGbwpQCGL-"
      },
      "source": [
        "Let's show you what we mean:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tqNdJjfrCGL-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# A numpy array zeros\n",
        "score = np.zeros((num_nonterminals,\n",
        "                  num_words + 1,\n",
        "                  num_words + 1))\n",
        "\n",
        "# A numpy array that can store arbitrary data (we set dtype to object)\n",
        "back = np.zeros((num_nonterminals,\n",
        "                 num_words + 1,\n",
        "                 num_words + 1), dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0YJ227uCGL-"
      },
      "source": [
        "The following illustrates the way you will use the `back` chart. In this example, your parser recognized that the entire sequence is S while the words between 0 and 2 form NP, and the words between 2 and the end of the sentence form VP (and nothing else yet):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7KOKnTuCGL_",
        "outputId": "b93ac01b-c971-48e9-d647-c1af96f09c59",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, (2, Nonterminal('NP'), Nonterminal('VP'))],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]]], dtype=object)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Illustration of the backpointer array\n",
        "back[n2i[S]][0][-1] = (2,NP,VP)\n",
        "back"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkUx3Mc5CGL_"
      },
      "source": [
        "## Ex1 [60pt] CKY parsing\n",
        "\n",
        "Implement the **CKY** algorithm. Follow the pseudo-code given in the lecture-slides (or alternatively in J&M). The code must comply to the following:\n",
        "\n",
        "* The function `cky` takes a sentence (list of words), a grammar (an instance of PCFG), and a n2i non-terminals-to-index dictionary.\n",
        "* The function `cky` returns the filled-in score-chart and backpointer-chart, following the format established above.\n",
        "* No global variables should be accessed from the body of the function (except for the predefined classes).\n",
        "\n",
        "**[Hint]** This is the moment to make good use of the methods of the classes `PCFG`, `Rule`, `Nonterminal`, and `Terminal`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6Kq23wsvCGL_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cky(sentence, grammar, n2i):\n",
        "    \"\"\"\n",
        "    The CKY algorithm.\n",
        "\n",
        "    :param sentence: a list of words\n",
        "    :param grammar: an instance of the class PCFG\n",
        "    :param n2i: a dictionary mapping from Nonterminals to indices\n",
        "    :return score: the filled in scores chart\n",
        "    :return back: the filled in backpointers chart\n",
        "    \"\"\"\n",
        "    num_words = len(sentence)\n",
        "    num_nonterminals = len(grammar.nonterminals)\n",
        "\n",
        "    # A numpy array to store the scores of intermediate parses\n",
        "    score = np.zeros((num_nonterminals,\n",
        "                  num_words + 1,\n",
        "                  num_words + 1))\n",
        "\n",
        "    # A numpy array to store the backpointers\n",
        "    back = np.zeros((num_nonterminals,\n",
        "                     num_words + 1,\n",
        "                     num_words + 1), dtype=object)\n",
        "    # Initialize an empty table that will store the parsing information.\n",
        "\n",
        "    for j in range(num_words):\n",
        "      for A in grammar.nonterminals:\n",
        "        rules = grammar.get(A)\n",
        "        for rule in rules:\n",
        "          if rule.is_unary() and str(rule.rhs[0]) == str(Terminal(sentence[j])):\n",
        "\n",
        "                  back[n2i[A]][j][j+1] = (j, rule.rhs[0])\n",
        "                  score[n2i[A]][j][j+1] = rule.prob\n",
        "\n",
        "\n",
        "    # Fill in the upper triangular part of the CYK table\n",
        "    for length in range(2, num_words+1 ):  #how many pairs of words we are considering\n",
        "        for i in range(num_words - length +1):\n",
        "            j = i + length -1\n",
        "            for k in range(i, j+1):\n",
        "\n",
        "                B = back[:, i, k]\n",
        "                C = back[:, k, j+1]\n",
        "\n",
        "                B_score = score[:, i, k]\n",
        "                C_score = score[:, k, j+1]\n",
        "\n",
        "                for A in grammar.nonterminals:\n",
        "                    rules = grammar.get(A)\n",
        "                    condition_satisfied = False\n",
        "\n",
        "\n",
        "                    for rule in rules:\n",
        "\n",
        "                      if rule.is_binary():\n",
        "\n",
        "                        condition_B_1 = [isinstance(element, tuple) for element in B]\n",
        "                        condition_C_1 = [isinstance(element, tuple) for element in C]\n",
        "\n",
        "                        if np.any(condition_B_1) and np.any(condition_C_1):\n",
        "\n",
        "                          indice_B = np.where(condition_B_1)[0]\n",
        "                          indice_C = np.where(condition_C_1)[0]\n",
        "\n",
        "                          if indice_B[0] == n2i[rule.rhs[0]] and indice_C[0] == n2i[rule.rhs[1]]:\n",
        "\n",
        "                              A = rule.lhs\n",
        "                              back[n2i[A]][i][j+1] = (k, rule.rhs[0], rule.rhs[1])\n",
        "\n",
        "                              #Calculate probability by multiplyiing probabilities of previous cells\n",
        "\n",
        "                              probability = sum(B_score) * sum(C_score) * rule.prob\n",
        "                              if score[n2i[A]][i][j+1] !=0:\n",
        "                                if probability > score[n2i[A]][i][j+1]:\n",
        "                                  score[n2i[A]][i][j+1] = probability\n",
        "                                continue\n",
        "\n",
        "                              score[n2i[A]][i][j+1] = sum(B_score) * sum(C_score) * rule.prob\n",
        "\n",
        "\n",
        "\n",
        "    return score, back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DdyvogQICGMA"
      },
      "outputs": [],
      "source": [
        "# Run CKY\n",
        "score, back = cky(sentence, grammar, n2i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-RR3hKxCGMA"
      },
      "source": [
        "### Check your CKY\n",
        "\n",
        "Use the code in the following two cell to check your `cky` implementation.\n",
        "\n",
        "Take the Nonterminal `S` to inspect your filled in score and backpointer charts. **Leave the code in this cell unchanged.** We will use this to evaluate the corectness of your cky function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBvi4nElCGMB",
        "outputId": "3d98b98f-b940-45c3-d25e-34fb0d7f7e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The whole slice for nonterminal S:\n",
            "[[0.        0.        0.        0.        0.0048    0.        0.\n",
            "  0.0001152]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]\n",
            " [0.        0.        0.        0.        0.        0.        0.\n",
            "  0.       ]] \n",
            "\n",
            "The score in cell (S, 0, num_words), which is the probability of the best parse:\n",
            "0.00011520000000000004 \n",
            "\n",
            "The backpointer in cell (S, 0, num_words):\n",
            "(1, Nonterminal('NP'), Nonterminal('VP')) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TEST EX1\n",
        "### Don't change the code in this cell ###\n",
        "\n",
        "S = Nonterminal('S')\n",
        "\n",
        "print('The whole slice for nonterminal S:')\n",
        "print(score[n2i[S]], \"\\n\")\n",
        "\n",
        "print('The score in cell (S, 0, num_words), which is the probability of the best parse:')\n",
        "print(score[n2i[S]][0][num_words], \"\\n\")\n",
        "\n",
        "print('The backpointer in cell (S, 0, num_words):')\n",
        "print(back[n2i[S]][0][num_words], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFo5ehEACGMC"
      },
      "source": [
        "## Ex2 [40pt] Recovering a tree\n",
        "\n",
        "Write the function `build_tree` that reconstructs the parse from the backpointer table. This is the function that is called in the return statement of the [pseudo-code](https://web.stanford.edu/~jurafsky/slp3/C.pdf#page=6) in Jurafsky and Martin.\n",
        "\n",
        "**[Note]** We have no pseudocode for you here: you must come up with your own implementation. However we do provide you with the expected output so that you can at least partially test your code.\n",
        "\n",
        "Here is some additional advice:\n",
        "\n",
        "* Use recursion - that is write your function in a recursive way.\n",
        "What is the base case? Hint: $A \\to w$.\n",
        "What is the recursive case? Hint: $A \\to B\\; C$.\n",
        "\n",
        "\n",
        "* Use the additional class `Span` that we introduce below for the symbols in your recovered rules. Read the documentation in the `Span` class for its usage.\n",
        "\n",
        "\n",
        "* In order to use the function `make_nltk_tree` (which we provide and that turns a `derivation` into an NLTK tree so that you can draw it), your function must return the <font color=\"red\">**list of rules in derivation ordered [depth-first](https://en.wikipedia.org/wiki/Depth-first_search)**</font>. If you write your function recursively such order can be achieved easily.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyYrjUP9CGMC"
      },
      "source": [
        "The following class will be very useful in your solution for the function `build_tree`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ty0jbFeuCGMD"
      },
      "outputs": [],
      "source": [
        "class Span(Symbol):\n",
        "    \"\"\"\n",
        "    A Span indicates that symbol was recognized between begin and end.\n",
        "\n",
        "    Example:\n",
        "        Span(Terminal('the'), 0, 1)\n",
        "            This means: we found 'the' in the sentence between 0 and 1\n",
        "        Span(Nonterminal('NP'), 4, 8) represents NP:4-8\n",
        "            This means: we found an NP that covers the part of the sentence between 4 and 8\n",
        "\n",
        "    Thus, Span holds a Terminal or a Nonterminal and wraps it between two integers.\n",
        "    This makes it possible to distinguish between two instances of the same rule in the derivation.\n",
        "    Example:\n",
        "        We can find that the rule NP -> Det N is used twice in the parse derivation. But that in the first\n",
        "        case it spans \"an elephant\" and in the second case it spans \"my pajamas\". We want to distinguis these.\n",
        "        So: \"an elephant\" is covered by [NP]:2-4 -> [Det]:2-3 [N]:3-4\n",
        "            \"my pajamas\" is covered by [NP]:5-7 -> [Det]:5-6 [N]:6-7\n",
        "\n",
        "    Internally, we represent spans with tuples of the kind (symbol, start, end).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, symbol, start, end):\n",
        "        assert isinstance(symbol, Symbol), f\"A span takes an instance of Symbol, got {type(symbol)}\"\n",
        "        self._symbol = symbol\n",
        "        self._start = start\n",
        "        self._end = end\n",
        "\n",
        "    def is_terminal(self):\n",
        "        # a span delegates this to an underlying symbol\n",
        "        return self._symbol.is_terminal()\n",
        "\n",
        "    def obj(self):\n",
        "        \"\"\"The underlying python tuple (Symbol, start, end)\"\"\"\n",
        "        return (self._symbol, self._start, self._end)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Prints Symbol surrounded with begin and end (purely aesthetics)\"\"\"\n",
        "        return f\"{self._start}:{self._symbol}:{self._end}\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Span({self._symbol!r}, {self._start!r}, {self._end!r})\"\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self._symbol, self._start, self._end))\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return type(self) == type(other) and self._symbol == other._symbol and self._start == other._start and self._end == other._end\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not (self == other)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW5SsW6sCGMD"
      },
      "source": [
        "Example usage of `Span`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwn43NFYCGME",
        "outputId": "9b7a3d09-9b4a-4ab5-9a02-fef17f9d5817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:[S]:10\n",
            "4:'dog':5\n",
            "2:[NP]:4 -> 2:[Det]:3 3:[NP]:4 (None)\n"
          ]
        }
      ],
      "source": [
        "span_S = Span(S, 0, 10)\n",
        "print(span_S)\n",
        "span_S = Span(dog, 4, 5)\n",
        "print(span_S)\n",
        "\n",
        "spanned_rule = Rule(Span(NP, 2, 4), [Span(Det, 2, 3), Span(NP, 3, 4)], prob=None)\n",
        "print(spanned_rule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E4CFhArSpLL"
      },
      "source": [
        "Your final derivation should look like this:\n",
        "\n",
        "```\n",
        "[0:[S]:7 -> 0:[NP]:1 1:[VP]:7 (None),\n",
        " 0:[NP]:1 -> 0:'I':1 (None),\n",
        " 1:[VP]:7 -> 1:[VP]:4 4:[PP]:7 (None),\n",
        " 1:[VP]:4 -> 1:[V]:2 2:[NP]:4 (None),\n",
        " 1:[V]:2 -> 1:'shot':2 (None),\n",
        " 2:[NP]:4 -> 2:[Det]:3 3:[N]:4 (None),\n",
        " 2:[Det]:3 -> 2:'an':3 (None),\n",
        " 3:[N]:4 -> 3:'elephant':4 (None),\n",
        " 2:[NP]:4 -> 2:[Det]:3 3:[N]:4 (None),\n",
        " 1:[VP]:4 -> 1:[V]:2 2:[NP]:4 (None),\n",
        " 4:[PP]:7 -> 4:[P]:5 5:[NP]:7 (None),\n",
        " 4:[P]:5 -> 4:'in':5 (None),\n",
        " 5:[NP]:7 -> 5:[Det]:6 6:[N]:7 (None),\n",
        " 5:[Det]:6 -> 5:'my':6 (None),\n",
        " 6:[N]:7 -> 6:'pajamas':7 (None),\n",
        " 5:[NP]:7 -> 5:[Det]:6 6:[N]:7 (None),\n",
        " 4:[PP]:7 -> 4:[P]:5 5:[NP]:7 (None),\n",
        " 1:[VP]:7 -> 1:[VP]:4 4:[PP]:7 (None)]\n",
        "```\n",
        "\n",
        "(Note that the rule probabilities are set to `None`. These are not saved in the backpointer chart so cannot be retrieved at the recovering stage. They also don't matter at this point, so you can set them to `None`.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3tD8G4MCGMF"
      },
      "source": [
        "### build_tree function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "n5iPPQ9kCGMF"
      },
      "outputs": [],
      "source": [
        "def build_tree(back, sentence, root, n2i):\n",
        "    \"\"\"\n",
        "    Reconstruct the viterbi parse from a filled-in backpointer chart.\n",
        "\n",
        "    It returns a list called derivation which holds the rules over Spans.\n",
        "    In order to use the function make_nltk_tree for the output,\n",
        "    you must make sure that the order in derivation follows the depth-first order.\n",
        "\n",
        "    :param back: a backpointer chart of shape [num_nonterminals, num_words+1, num_words+1]\n",
        "    :param sentence: a list of words\n",
        "    :param root: the root symbol of the tree: usually Nonterminal('S')\n",
        "    :param n2i: the dictionary mapping from Nonterminals to indices\n",
        "    :return derivation: a derivation: a list of Rules with Span symbols that generate the Viterbi tree.\n",
        "                        The list should be ordered depth first!\n",
        "    \"\"\"\n",
        "    derivation = []\n",
        "    num_words = len(sentence)\n",
        "    ### YOUR CODE HERE ###\n",
        "\n",
        "    def dfs(symbol, start, end, back):\n",
        "        if start + 1 == end:\n",
        "            _, terminal = back[n2i[symbol]][start][end]\n",
        "            return [Rule(Span(symbol, start, end), [Span(terminal, start, end)], prob=None)]\n",
        "\n",
        "        split_idx, left, right = back[n2i[symbol]][start][end]\n",
        "\n",
        "        lhs = Span(symbol, start, end)\n",
        "        rhs = [Span(left, start, split_idx), Span(right, split_idx, end)]\n",
        "        rule = Rule(lhs, rhs, prob=None)\n",
        "\n",
        "        return [rule] + dfs(left, start, split_idx, back) + dfs(right, split_idx, end, back)\n",
        "\n",
        "    derivation = dfs(root, 0, num_words, back)\n",
        "\n",
        "    return derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C-x98b5CGMG"
      },
      "source": [
        "Get your derivation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZCWB9n8CGMG",
        "outputId": "c47f9972-7da9-4bae-f038-807f1b827e0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0:[S]:7 -> 0:[NP]:1 1:[VP]:7 (None),\n",
              " 0:[NP]:1 -> 0:'I':1 (None),\n",
              " 1:[VP]:7 -> 1:[VP]:4 4:[PP]:7 (None),\n",
              " 1:[VP]:4 -> 1:[V]:2 2:[NP]:4 (None),\n",
              " 1:[V]:2 -> 1:'shot':2 (None),\n",
              " 2:[NP]:4 -> 2:[Det]:3 3:[N]:4 (None),\n",
              " 2:[Det]:3 -> 2:'an':3 (None),\n",
              " 3:[N]:4 -> 3:'elephant':4 (None),\n",
              " 4:[PP]:7 -> 4:[P]:5 5:[NP]:7 (None),\n",
              " 4:[P]:5 -> 4:'in':5 (None),\n",
              " 5:[NP]:7 -> 5:[Det]:6 6:[N]:7 (None),\n",
              " 5:[Det]:6 -> 5:'my':6 (None),\n",
              " 6:[N]:7 -> 6:'pajamas':7 (None)]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "derivation = build_tree(back, sentence, S, n2i)\n",
        "derivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7hKnXenUcyk"
      },
      "source": [
        "### Draw the tree\n",
        "\n",
        "Turn the derivation into an NLTK tree:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "OKPgJ9q5CGMG"
      },
      "outputs": [],
      "source": [
        "def make_nltk_tree(derivation):\n",
        "    \"\"\"\n",
        "    Return a NLTK Tree object based on the derivation\n",
        "    (list or tuple of Rules)\n",
        "    \"\"\"\n",
        "    d = defaultdict(None, ((r.lhs, r.rhs) for r in derivation))\n",
        "\n",
        "    def make_tree(lhs):\n",
        "        return Tree(str(lhs), (str(child) if child not in d else make_tree(child) for child in d[lhs]))\n",
        "\n",
        "    return make_tree(derivation[0].lhs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhh7YJLMUoIa"
      },
      "source": [
        "If you give the derivation to the function `make_nltk_tree` and let NLTK draw it, then you get this tree:\n",
        "\n",
        "```\n",
        "          0:[S]:7\n",
        "    _________|_______________________________\n",
        "   |                                      1:[VP]:7\n",
        "   |                     ____________________|_____________________\n",
        "   |                 1:[VP]:4                                   4:[PP]:7\n",
        "   |          __________|________                         _________|________\n",
        "   |         |                2:[NP]:4                   |               5:[NP]:7\n",
        "   |         |           ________|___________            |          ________|___________\n",
        "0:[NP]:1  1:[V]:2   2:[Det]:3             3:[N]:4     4:[P]:5  5:[Det]:6             6:[N]:7\n",
        "   |         |          |                    |           |         |                    |\n",
        "0:'I':1  1:'shot':2  2:'an':3          3:'elephant':4 4:'in':5  5:'my':6          6:'pajamas':7\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8KwEzfKNHsG",
        "outputId": "c45b3aea-9f45-420b-b4bb-eb5dfd9203d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          0:[S]:7                                                                              \n",
            "    _________|_______________________________                                                   \n",
            "   |                                      1:[VP]:7                                             \n",
            "   |                     ____________________|_____________________                             \n",
            "   |                 1:[VP]:4                                   4:[PP]:7                       \n",
            "   |          __________|________                         _________|________                    \n",
            "   |         |                2:[NP]:4                   |               5:[NP]:7              \n",
            "   |         |           ________|___________            |          ________|___________        \n",
            "0:[NP]:1  1:[V]:2   2:[Det]:3             3:[N]:4     4:[P]:5  5:[Det]:6             6:[N]:7   \n",
            "   |         |          |                    |           |         |                    |       \n",
            "0:'I':1  1:'shot':2  2:'an':3          3:'elephant':4 4:'in':5  5:'my':6          6:'pajamas':7\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TEST EX2\n",
        "tree = make_nltk_tree(derivation)\n",
        "tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KpnoxfjCGMH"
      },
      "source": [
        "# That's it!\n",
        "\n",
        "Congratulations, you have made it to the end of the lab.\n",
        "\n",
        "**Make sure all your cells are executed so that all your answers are there. Then, continue if you're interested!**\n",
        "\n",
        "----\n",
        "\n",
        "# Optional\n",
        "\n",
        "If you managed to get your entire CKY-parser working and have an appetite for more, it might be fun to try it on some more sentences and grammars. Give the grammars below a try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQXFftl-CGMH"
      },
      "source": [
        "### Alternative Groucho-grammar\n",
        "\n",
        "If you change the probabilities in the grammar, you'll get a different parse as the most likely one. Compare `groucho-grammar-1.txt` with `groucho-grammar-2.txt` and spot the difference in probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmKzOKOrCGMH"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQvNMXcpCGMI"
      },
      "source": [
        "### The man with the telescope\n",
        "\n",
        "Another ambiguous sentence:\n",
        "\n",
        "> I saw the man on the hill with the telescope.\n",
        "\n",
        "A grammar for this sentence is specified in the file `telescope-grammar.txt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saH1dFIkCGMI",
        "outputId": "5046607a-7787-449e-a2a5-9bcce954186f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The grammar:\n",
            " [S] -> [NP] [VP] (1.0)\n",
            "[VP] -> [V] [NP] (0.6)\n",
            "[VP] -> [VP] [PP] (0.4)\n",
            "[NP] -> [NP] [PP] (0.3)\n",
            "[NP] -> [Det] [N] (0.3)\n",
            "[NP] -> [Det] [NP] (0.2)\n",
            "[NP] -> 'I' (0.2)\n",
            "[PP] -> [P] [NP] (0.8)\n",
            "[PP] -> [PP] [PP] (0.2)\n",
            "[V] -> 'saw' (1.0)\n",
            "[Det] -> 'the' (1.0)\n",
            "[N] -> 'man' (0.4)\n",
            "[N] -> 'hill' (0.3)\n",
            "[N] -> 'telescope' (0.3)\n",
            "[P] -> 'on' (0.5)\n",
            "[P] -> 'with' (0.5)\n",
            "The whole slice for nonterminal S:\n",
            "[[0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.440000e-02\n",
            "  0.000000e+00 0.000000e+00 2.073600e-04 0.000000e+00 0.000000e+00\n",
            "  2.985984e-06]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]\n",
            " [0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
            "  0.000000e+00]] \n",
            "\n",
            "The score in cell (S, 0, num_words), which is the probability of the best parse:\n",
            "2.9859839999999994e-06 \n",
            "\n",
            "The backpointer in cell (S, 0, num_words):\n",
            "(1, Nonterminal('NP'), Nonterminal('VP')) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "## YOUR CODE HERE ##\n",
        "\n",
        "# Read in the grammar\n",
        "with open('telescope-grammar.txt') as F:\n",
        "    grammar_2 = PCFG(read_grammar_rules(F))\n",
        "print(\"The grammar:\\n\", grammar_2)\n",
        "\n",
        "\n",
        "num_nonterminals_2 = len(grammar_2.nonterminals)\n",
        "\n",
        "# Make a nonterminal2index and a index2nonterminal dictionary\n",
        "n2i_2 = defaultdict(lambda: len(n2i_2))\n",
        "i2n_2 = dict()\n",
        "\n",
        "# Turn the sentence into a list\n",
        "sentence_2 = \"I saw the man on the hill with the telescope\".split()\n",
        "\n",
        "# The length of the sentence\n",
        "num_words_2 = len(sentence_2)\n",
        "\n",
        "# sort nonterminals to make the mapping deterministic\n",
        "for nt in sorted(grammar_2.nonterminals):\n",
        "    i2n_2[n2i_2[nt]] = nt\n",
        "\n",
        "# Stop defaultdict behavior of n2i\n",
        "n2i_2 = dict(n2i)\n",
        "\n",
        "#Run CYK algorithm\n",
        "score_2, back_2 = cky(sentence_2, grammar_2, n2i_2)\n",
        "\n",
        "\n",
        "#Test code\n",
        "S_2 = Nonterminal('S')\n",
        "\n",
        "print('The whole slice for nonterminal S:')\n",
        "print(score_2[n2i[S]], \"\\n\")\n",
        "\n",
        "print('The score in cell (S, 0, num_words), which is the probability of the best parse:')\n",
        "print(score_2[n2i[S]][0][num_words_2], \"\\n\")\n",
        "\n",
        "\n",
        "print('The backpointer in cell (S, 0, num_words):')\n",
        "print(back_2[n2i[S]][0][num_words_2], \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxKPNeX3d09V",
        "outputId": "70c63a47-2901-4e47-96e1-c995de249757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                0:[S]:10                                                                              \n",
            "    _______________________________________________|_________                                                                          \n",
            "   |                                                     1:[VP]:10                                                                    \n",
            "   |                                       __________________|________________________________________                                 \n",
            "   |                                   1:[VP]:7                                                       |                               \n",
            "   |                    __________________|__________________                                         |                                \n",
            "   |                1:[VP]:4                              4:[PP]:7                                7:[PP]:10                           \n",
            "   |          _________|________                    _________|________                      __________|_________                       \n",
            "   |         |               2:[NP]:4              |               5:[NP]:7                |                8:[NP]:10                 \n",
            "   |         |          ________|_________         |          ________|_________           |           _________|____________          \n",
            "0:[NP]:1  1:[V]:2  2:[Det]:3           3:[N]:4  4:[P]:5  5:[Det]:6           6:[N]:7    7:[P]:8   8:[Det]:9               9:[N]:10    \n",
            "   |         |         |                  |        |         |                  |          |          |                      |         \n",
            "0:'I':1  1:'saw':2 2:'the':3          3:'man':4 4:'on':5 5:'the':6          6:'hill':7 7:'with':8 8:'the':9           9:'telescope':10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "derivation_2 = build_tree(back_2, sentence_2, S_2, n2i_2)\n",
        "tree_2 = make_nltk_tree(derivation_2)\n",
        "tree_2.pretty_print()"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
